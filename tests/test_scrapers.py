import sys
import os
import asyncio

# Add parent directory to path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from scraper.yad2_scraper import Yad2Scraper
from models.listing import Listing


async def test_yad2_scraper_basic():
    """Test basic Yad2Scraper functionality"""
    print("ğŸ  Testing Yad2Scraper Basic Functionality...")
    print("=" * 50)

    try:
        # Create scraper
        scraper = Yad2Scraper()
        print(f"âœ… Scraper created: {scraper}")

        # Test criteria loading
        print(f"âœ… Loaded criteria: {scraper.criteria}")

        # Test URL building
        search_url = scraper._build_search_url()
        print(f"âœ… Search URL: {search_url}")

        # Test scraper properties
        print(f"âœ… Base URL: {scraper.base_url}")
        print(f"âœ… Search URL: {scraper.search_url}")

        return scraper

    except Exception as e:
        print(f"âŒ Error in basic test: {e}")
        return None


async def test_yad2_scraper_url_building():
    """Test URL building with different parameters"""
    print("\nğŸ”— Testing URL Building...")
    print("=" * 50)

    try:
        scraper = Yad2Scraper()

        # Test URL building
        url = scraper._build_search_url()
        print(f"âœ… Generated URL: {url}")

        # Check if URL contains expected parameters
        if "price_from" in url:
            print("âœ… URL contains price_from parameter")
        else:
            print("âš ï¸  URL missing price_from parameter")

        if "price_to" in url:
            print("âœ… URL contains price_to parameter")
        else:
            print("âš ï¸  URL missing price_to parameter")

        if "city" in url:
            print("âœ… URL contains city parameter")
        else:
            print("âš ï¸  URL missing city parameter")

        return True

    except Exception as e:
        print(f"âŒ Error in URL building test: {e}")
        return False


async def test_yad2_scraper_page_fetch():
    """Test fetching a page from Yad2"""
    print("\nğŸŒ Testing Page Fetching...")
    print("=" * 50)

    try:
        scraper = Yad2Scraper()

        # Build search URL
        search_url = scraper._build_search_url()
        print(f"ğŸ” Fetching URL: {search_url}")

        # Try to fetch the page
        html_content = await scraper._fetch_page(search_url)

        if html_content:
            print(f"âœ… Page fetched successfully!")
            print(f"ğŸ“„ Content length: {len(html_content)} characters")

            # Check if it looks like a Yad2 page
            if "yad2" in html_content.lower():
                print("âœ… Content appears to be from Yad2")
            else:
                print("âš ï¸  Content doesn't appear to be from Yad2")

            return True
        else:
            print("âŒ Failed to fetch page")
            return False

    except Exception as e:
        print(f"âŒ Error fetching page: {e}")
        return False
    finally:
        await scraper.close()


async def test_yad2_scraper_real():
    """Test actual scraping from Yad2"""
    print("\nğŸ—ï¸  Testing Real Yad2 Scraping...")
    print("=" * 50)

    scraper = Yad2Scraper()

    try:
        # This will try to scrape real listings
        print("ğŸ” Starting scrape...")
        listings = await scraper.scrape()

        print(f"âœ… Scraping completed!")
        print(f"ğŸ“‹ Found {len(listings)} listings")

        if listings:
            print(f"\nğŸ“Š Sample listings:")
            # Show first few listings
            for i, listing in enumerate(listings[:3]):
                print(f"\nğŸ“‹ Listing {i + 1}:")
                print(f"   Title: {listing.title}")
                print(f"   Price: {listing.price}â‚ª")
                print(f"   Rooms: {listing.number_of_rooms}")
                print(f"   Location: {listing.location}")
                print(f"   URL: {listing.url}")
                print(f"   Description: {listing.description[:100]}...")

            # Check data quality
            valid_listings = [l for l in listings if l.title and l.price > 0 and l.number_of_rooms > 0]
            print(f"\nâœ… Valid listings: {len(valid_listings)}/{len(listings)}")

            if valid_listings:
                print("âœ… Found listings with valid data!")
            else:
                print("âš ï¸  No listings have valid data - may need to update CSS selectors")

        else:
            print("âš ï¸  No listings found - may need to update CSS selectors or check website structure")

        return listings

    except Exception as e:
        print(f"âŒ Error during scraping: {e}")
        import traceback
        traceback.print_exc()
        return []

    finally:
        # Clean up
        await scraper.close()


async def test_extraction_methods():
    """Test individual extraction methods with sample HTML"""
    print("\nğŸ”§ Testing Extraction Methods...")
    print("=" * 50)

    try:
        scraper = Yad2Scraper()

        # Create sample HTML element (this is just for testing the methods)
        from bs4 import BeautifulSoup
        sample_html = """
        <div class="feeditem">
            <h2>×“×™×¨×” ×™×¤×” ×‘×‘×ª ×’×œ×™×</h2>
            <div class="price">3,500â‚ª</div>
            <div class="rooms">3 ×—×“×¨×™×</div>
            <div class="location">×‘×ª ×’×œ×™×, ×—×™×¤×”</div>
            <a href="/rent/apartment/12345">Link to listing</a>
        </div>
        """

        soup = BeautifulSoup(sample_html, 'html.parser')
        element = soup.find('div', class_='feeditem')

        # Test extraction methods
        title = scraper._extract_title(element)
        price = scraper._extract_price(element)
        rooms = scraper._extract_rooms(element)
        location = scraper._extract_location(element)
        url = scraper._extract_url(element)

        print(f"âœ… Title extraction: '{title}'")
        print(f"âœ… Price extraction: {price}")
        print(f"âœ… Rooms extraction: {rooms}")
        print(f"âœ… Location extraction: '{location}'")
        print(f"âœ… URL extraction: '{url}'")

        # Check if extractions worked
        success = bool(title and price > 0 and rooms > 0 and location)
        print(f"âœ… Extraction test: {'PASSED' if success else 'FAILED'}")

        return success

    except Exception as e:
        print(f"âŒ Error in extraction test: {e}")
        return False


async def main():
    """Run all scraper tests"""
    print("ğŸ” Testing Yad2 Scraper")
    print("=" * 60)

    results = {}

    # Test basic functionality
    print("Phase 1: Basic functionality")
    scraper = await test_yad2_scraper_basic()
    results['basic'] = scraper is not None

    # Test URL building
    print("\nPhase 2: URL building")
    results['url'] = await test_yad2_scraper_url_building()

    # Test page fetching
    print("\nPhase 3: Page fetching")
    results['fetch'] = await test_yad2_scraper_page_fetch()

    # Test extraction methods
    print("\nPhase 4: Extraction methods")
    results['extraction'] = await test_extraction_methods()

    # Test real scraping
    print("\nPhase 5: Real scraping")
    listings = await test_yad2_scraper_real()
    results['scraping'] = len(listings) > 0

    # Final summary
    print("\n" + "=" * 60)
    print("ğŸ“Š FINAL TEST SUMMARY:")
    print("=" * 60)

    for test_name, passed in results.items():
        status = "âœ… PASSED" if passed else "âŒ FAILED"
        print(f"{test_name.upper():<15} {status}")

    total_passed = sum(results.values())
    total_tests = len(results)

    print(f"\nOverall: {total_passed}/{total_tests} tests passed ({total_passed / total_tests * 100:.1f}%)")

    if results['scraping']:
        print("\nğŸ‰ SUCCESS: Scraper is working and finding listings!")
        print(f"ğŸ“‹ Found {len(listings)} listings from Yad2")
    else:
        print("\nâš ï¸  PARTIAL SUCCESS: Basic functionality works")
        print("ğŸ”§ Need to inspect Yad2 HTML structure and update CSS selectors")

    print("\nğŸ’¡ Next steps:")
    if not results['scraping']:
        print("   1. Run the scraper and check what HTML structure Yad2 actually uses")
        print("   2. Update CSS selectors in the extraction methods")
        print("   3. Test again")
    else:
        print("   1. Integrate with database and filters")
        print("   2. Add more sophisticated extraction logic")
        print("   3. Build the notification system")


if __name__ == "__main__":
    asyncio.run(main())